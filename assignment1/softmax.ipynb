{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.335597\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "import random\n",
    "random.seed = 17\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** *Fill this in*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -1.242477 analytic: -1.242477, relative error: 1.129796e-08\n",
      "numerical: -0.872214 analytic: -0.872214, relative error: 2.581137e-08\n",
      "numerical: -1.747568 analytic: -1.747568, relative error: 1.930169e-09\n",
      "numerical: -0.258495 analytic: -0.258495, relative error: 7.451779e-08\n",
      "numerical: 0.230520 analytic: 0.230521, relative error: 2.228269e-07\n",
      "numerical: 2.525056 analytic: 2.525056, relative error: 1.039303e-08\n",
      "numerical: 0.669212 analytic: 0.669212, relative error: 5.097189e-08\n",
      "numerical: 0.611629 analytic: 0.611629, relative error: 4.013097e-08\n",
      "numerical: 0.353985 analytic: 0.353985, relative error: 2.836468e-08\n",
      "numerical: 0.834249 analytic: 0.834249, relative error: 9.805061e-08\n",
      "numerical: -0.602461 analytic: -0.602461, relative error: 5.285553e-08\n",
      "numerical: -0.771207 analytic: -0.771207, relative error: 4.311038e-08\n",
      "numerical: -2.548515 analytic: -2.548515, relative error: 2.216729e-08\n",
      "numerical: 3.005058 analytic: 3.005058, relative error: 1.893761e-08\n",
      "numerical: 3.114313 analytic: 3.114313, relative error: 1.106834e-08\n",
      "numerical: 0.738945 analytic: 0.738945, relative error: 7.372541e-09\n",
      "numerical: -2.426648 analytic: -2.426648, relative error: 1.585298e-08\n",
      "numerical: 2.065573 analytic: 2.065573, relative error: 1.649538e-08\n",
      "numerical: -0.212602 analytic: -0.212602, relative error: 4.516955e-09\n",
      "numerical: 0.473094 analytic: 0.473094, relative error: 6.100714e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_dev.copy()\n",
    "y = y_dev.copy()\n",
    "loss = 0.0\n",
    "dW = np.zeros_like(W)\n",
    "##############################################################\n",
    "num_train = X.shape[0]\n",
    "num_classes = W.shape[1]\n",
    "\n",
    "scores = X.dot(W)\n",
    "\n",
    "scores.shape\n",
    "\n",
    "\n",
    "# loss += -np.log(sigma)\n",
    "\n",
    "\n",
    "# loss /= num_train\n",
    "# dW /= num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3355974901668146"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = np.exp(scores) / np.reshape(np.sum(np.exp(scores), axis=1), (num_train, -1))\n",
    "\n",
    "np.sum(-np.log(sigma[range(y.shape[0]), y])) / num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3355974901668146"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(-np.log(sigma[range(y.shape[0]), y])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 3073), (500, 10))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 231.04519801,  220.40015578, -762.5434223 , ..., -220.2849514 ,\n",
       "         541.46469743, -240.3035524 ],\n",
       "       [ 167.51798532,  220.78463018, -756.81035684, ..., -389.22532003,\n",
       "         438.26794106,  -89.19130361],\n",
       "       [ -73.65137634,  261.35487652, -821.12279555, ..., -624.84468803,\n",
       "         390.00621642,   25.79477555],\n",
       "       ...,\n",
       "       [ 271.89113431,  261.59287662,  112.8921388 , ..., -271.83153383,\n",
       "          24.85112232, -222.56919374],\n",
       "       [   8.10197825,  284.96317924,   57.83975136, ..., -434.86606565,\n",
       "          21.19106013, -161.75770683],\n",
       "       [  49.65656895,   47.93804949,   51.7911354 , ...,   51.13135092,\n",
       "          50.97350782,   48.72672448]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(X).dot(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.335597e+00 computed in 0.232209s\n",
      "vectorized loss: 2.335597e+00 computed in 0.013522s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7657237acf9046da816f247287984f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lr 1.000000e-08 reg 2.500000e+02 train accuracy: 0.101041 val accuracy: 0.123000\n",
      "lr 1.000000e-08 reg 5.000000e+02 train accuracy: 0.108306 val accuracy: 0.134000\n",
      "lr 1.000000e-08 reg 7.500000e+02 train accuracy: 0.115265 val accuracy: 0.140000\n",
      "lr 1.000000e-08 reg 1.000000e+03 train accuracy: 0.120429 val accuracy: 0.151000\n",
      "lr 1.000000e-08 reg 1.250000e+03 train accuracy: 0.125306 val accuracy: 0.154000\n",
      "lr 1.000000e-08 reg 1.500000e+03 train accuracy: 0.129490 val accuracy: 0.158000\n",
      "lr 1.000000e-08 reg 1.750000e+03 train accuracy: 0.133469 val accuracy: 0.157000\n",
      "lr 1.000000e-08 reg 2.000000e+03 train accuracy: 0.137633 val accuracy: 0.162000\n",
      "lr 1.000000e-08 reg 2.250000e+03 train accuracy: 0.142163 val accuracy: 0.168000\n",
      "lr 1.000000e-08 reg 2.500000e+03 train accuracy: 0.145490 val accuracy: 0.173000\n",
      "lr 1.000000e-08 reg 2.750000e+03 train accuracy: 0.149469 val accuracy: 0.175000\n",
      "lr 1.000000e-08 reg 3.000000e+03 train accuracy: 0.152653 val accuracy: 0.180000\n",
      "lr 1.000000e-08 reg 3.250000e+03 train accuracy: 0.156408 val accuracy: 0.182000\n",
      "lr 1.000000e-08 reg 3.500000e+03 train accuracy: 0.159673 val accuracy: 0.188000\n",
      "lr 1.000000e-08 reg 3.750000e+03 train accuracy: 0.162388 val accuracy: 0.194000\n",
      "lr 1.000000e-08 reg 4.000000e+03 train accuracy: 0.164429 val accuracy: 0.193000\n",
      "lr 1.000000e-08 reg 4.250000e+03 train accuracy: 0.166959 val accuracy: 0.194000\n",
      "lr 1.000000e-08 reg 4.500000e+03 train accuracy: 0.169388 val accuracy: 0.196000\n",
      "lr 1.000000e-08 reg 4.750000e+03 train accuracy: 0.171551 val accuracy: 0.196000\n",
      "lr 1.000000e-08 reg 5.000000e+03 train accuracy: 0.173878 val accuracy: 0.195000\n",
      "lr 2.726316e-07 reg 2.500000e+02 train accuracy: 0.214469 val accuracy: 0.253000\n",
      "lr 2.726316e-07 reg 5.000000e+02 train accuracy: 0.236776 val accuracy: 0.271000\n",
      "lr 2.726316e-07 reg 7.500000e+02 train accuracy: 0.249980 val accuracy: 0.286000\n",
      "lr 2.726316e-07 reg 1.000000e+03 train accuracy: 0.263184 val accuracy: 0.300000\n",
      "lr 2.726316e-07 reg 1.250000e+03 train accuracy: 0.275449 val accuracy: 0.314000\n",
      "lr 2.726316e-07 reg 1.500000e+03 train accuracy: 0.286143 val accuracy: 0.314000\n",
      "lr 2.726316e-07 reg 1.750000e+03 train accuracy: 0.293959 val accuracy: 0.321000\n",
      "lr 2.726316e-07 reg 2.000000e+03 train accuracy: 0.305265 val accuracy: 0.328000\n",
      "lr 2.726316e-07 reg 2.250000e+03 train accuracy: 0.316408 val accuracy: 0.329000\n",
      "lr 2.726316e-07 reg 2.500000e+03 train accuracy: 0.328918 val accuracy: 0.347000\n",
      "lr 2.726316e-07 reg 2.750000e+03 train accuracy: 0.338592 val accuracy: 0.363000\n",
      "lr 2.726316e-07 reg 3.000000e+03 train accuracy: 0.346082 val accuracy: 0.375000\n",
      "lr 2.726316e-07 reg 3.250000e+03 train accuracy: 0.355837 val accuracy: 0.373000\n",
      "lr 2.726316e-07 reg 3.500000e+03 train accuracy: 0.364633 val accuracy: 0.380000\n",
      "lr 2.726316e-07 reg 3.750000e+03 train accuracy: 0.368551 val accuracy: 0.383000\n",
      "lr 2.726316e-07 reg 4.000000e+03 train accuracy: 0.371592 val accuracy: 0.390000\n",
      "lr 2.726316e-07 reg 4.250000e+03 train accuracy: 0.371633 val accuracy: 0.385000\n",
      "lr 2.726316e-07 reg 4.500000e+03 train accuracy: 0.377735 val accuracy: 0.391000\n",
      "lr 2.726316e-07 reg 4.750000e+03 train accuracy: 0.375612 val accuracy: 0.388000\n",
      "lr 2.726316e-07 reg 5.000000e+03 train accuracy: 0.373122 val accuracy: 0.379000\n",
      "lr 5.352632e-07 reg 2.500000e+02 train accuracy: 0.381857 val accuracy: 0.380000\n",
      "lr 5.352632e-07 reg 5.000000e+02 train accuracy: 0.388551 val accuracy: 0.400000\n",
      "lr 5.352632e-07 reg 7.500000e+02 train accuracy: 0.391816 val accuracy: 0.396000\n",
      "lr 5.352632e-07 reg 1.000000e+03 train accuracy: 0.396184 val accuracy: 0.385000\n",
      "lr 5.352632e-07 reg 1.250000e+03 train accuracy: 0.397776 val accuracy: 0.401000\n",
      "lr 5.352632e-07 reg 1.500000e+03 train accuracy: 0.394184 val accuracy: 0.395000\n",
      "lr 5.352632e-07 reg 1.750000e+03 train accuracy: 0.395204 val accuracy: 0.392000\n",
      "lr 5.352632e-07 reg 2.000000e+03 train accuracy: 0.393510 val accuracy: 0.393000\n",
      "lr 5.352632e-07 reg 2.250000e+03 train accuracy: 0.393204 val accuracy: 0.401000\n",
      "lr 5.352632e-07 reg 2.500000e+03 train accuracy: 0.396306 val accuracy: 0.402000\n",
      "lr 5.352632e-07 reg 2.750000e+03 train accuracy: 0.384551 val accuracy: 0.385000\n",
      "lr 5.352632e-07 reg 3.000000e+03 train accuracy: 0.385306 val accuracy: 0.397000\n",
      "lr 5.352632e-07 reg 3.250000e+03 train accuracy: 0.386939 val accuracy: 0.400000\n",
      "lr 5.352632e-07 reg 3.500000e+03 train accuracy: 0.382551 val accuracy: 0.381000\n",
      "lr 5.352632e-07 reg 3.750000e+03 train accuracy: 0.379449 val accuracy: 0.383000\n",
      "lr 5.352632e-07 reg 4.000000e+03 train accuracy: 0.380429 val accuracy: 0.383000\n",
      "lr 5.352632e-07 reg 4.250000e+03 train accuracy: 0.373429 val accuracy: 0.374000\n",
      "lr 5.352632e-07 reg 4.500000e+03 train accuracy: 0.375571 val accuracy: 0.387000\n",
      "lr 5.352632e-07 reg 4.750000e+03 train accuracy: 0.372531 val accuracy: 0.387000\n",
      "lr 5.352632e-07 reg 5.000000e+03 train accuracy: 0.370367 val accuracy: 0.369000\n",
      "lr 7.978947e-07 reg 2.500000e+02 train accuracy: 0.384918 val accuracy: 0.393000\n",
      "lr 7.978947e-07 reg 5.000000e+02 train accuracy: 0.391673 val accuracy: 0.391000\n",
      "lr 7.978947e-07 reg 7.500000e+02 train accuracy: 0.394163 val accuracy: 0.396000\n",
      "lr 7.978947e-07 reg 1.000000e+03 train accuracy: 0.397122 val accuracy: 0.392000\n",
      "lr 7.978947e-07 reg 1.250000e+03 train accuracy: 0.396041 val accuracy: 0.393000\n",
      "lr 7.978947e-07 reg 1.500000e+03 train accuracy: 0.399959 val accuracy: 0.409000\n",
      "lr 7.978947e-07 reg 1.750000e+03 train accuracy: 0.389673 val accuracy: 0.404000\n",
      "lr 7.978947e-07 reg 2.000000e+03 train accuracy: 0.395959 val accuracy: 0.406000\n",
      "lr 7.978947e-07 reg 2.250000e+03 train accuracy: 0.392551 val accuracy: 0.393000\n",
      "lr 7.978947e-07 reg 2.500000e+03 train accuracy: 0.381061 val accuracy: 0.400000\n",
      "lr 7.978947e-07 reg 2.750000e+03 train accuracy: 0.385449 val accuracy: 0.400000\n",
      "lr 7.978947e-07 reg 3.000000e+03 train accuracy: 0.386102 val accuracy: 0.400000\n",
      "lr 7.978947e-07 reg 3.250000e+03 train accuracy: 0.378980 val accuracy: 0.379000\n",
      "lr 7.978947e-07 reg 3.500000e+03 train accuracy: 0.378102 val accuracy: 0.382000\n",
      "lr 7.978947e-07 reg 3.750000e+03 train accuracy: 0.375694 val accuracy: 0.386000\n",
      "lr 7.978947e-07 reg 4.000000e+03 train accuracy: 0.370408 val accuracy: 0.384000\n",
      "lr 7.978947e-07 reg 4.250000e+03 train accuracy: 0.370735 val accuracy: 0.386000\n",
      "lr 7.978947e-07 reg 4.500000e+03 train accuracy: 0.374102 val accuracy: 0.381000\n",
      "lr 7.978947e-07 reg 4.750000e+03 train accuracy: 0.375224 val accuracy: 0.372000\n",
      "lr 7.978947e-07 reg 5.000000e+03 train accuracy: 0.368714 val accuracy: 0.381000\n",
      "lr 1.060526e-06 reg 2.500000e+02 train accuracy: 0.388673 val accuracy: 0.399000\n",
      "lr 1.060526e-06 reg 5.000000e+02 train accuracy: 0.391347 val accuracy: 0.397000\n",
      "lr 1.060526e-06 reg 7.500000e+02 train accuracy: 0.398082 val accuracy: 0.392000\n",
      "lr 1.060526e-06 reg 1.000000e+03 train accuracy: 0.400857 val accuracy: 0.389000\n",
      "lr 1.060526e-06 reg 1.250000e+03 train accuracy: 0.398796 val accuracy: 0.389000\n",
      "lr 1.060526e-06 reg 1.500000e+03 train accuracy: 0.392959 val accuracy: 0.391000\n",
      "lr 1.060526e-06 reg 1.750000e+03 train accuracy: 0.388429 val accuracy: 0.393000\n",
      "lr 1.060526e-06 reg 2.000000e+03 train accuracy: 0.384633 val accuracy: 0.385000\n",
      "lr 1.060526e-06 reg 2.250000e+03 train accuracy: 0.385327 val accuracy: 0.395000\n",
      "lr 1.060526e-06 reg 2.500000e+03 train accuracy: 0.388367 val accuracy: 0.393000\n",
      "lr 1.060526e-06 reg 2.750000e+03 train accuracy: 0.381755 val accuracy: 0.382000\n",
      "lr 1.060526e-06 reg 3.000000e+03 train accuracy: 0.379000 val accuracy: 0.365000\n",
      "lr 1.060526e-06 reg 3.250000e+03 train accuracy: 0.373388 val accuracy: 0.375000\n",
      "lr 1.060526e-06 reg 3.500000e+03 train accuracy: 0.371673 val accuracy: 0.370000\n",
      "lr 1.060526e-06 reg 3.750000e+03 train accuracy: 0.375143 val accuracy: 0.375000\n",
      "lr 1.060526e-06 reg 4.000000e+03 train accuracy: 0.377306 val accuracy: 0.376000\n",
      "lr 1.060526e-06 reg 4.250000e+03 train accuracy: 0.370082 val accuracy: 0.383000\n",
      "lr 1.060526e-06 reg 4.500000e+03 train accuracy: 0.372020 val accuracy: 0.373000\n",
      "lr 1.060526e-06 reg 4.750000e+03 train accuracy: 0.366878 val accuracy: 0.369000\n",
      "lr 1.060526e-06 reg 5.000000e+03 train accuracy: 0.367061 val accuracy: 0.371000\n",
      "lr 1.323158e-06 reg 2.500000e+02 train accuracy: 0.386490 val accuracy: 0.392000\n",
      "lr 1.323158e-06 reg 5.000000e+02 train accuracy: 0.395388 val accuracy: 0.392000\n",
      "lr 1.323158e-06 reg 7.500000e+02 train accuracy: 0.399327 val accuracy: 0.398000\n",
      "lr 1.323158e-06 reg 1.000000e+03 train accuracy: 0.393306 val accuracy: 0.396000\n",
      "lr 1.323158e-06 reg 1.250000e+03 train accuracy: 0.397510 val accuracy: 0.390000\n",
      "lr 1.323158e-06 reg 1.500000e+03 train accuracy: 0.398694 val accuracy: 0.388000\n",
      "lr 1.323158e-06 reg 1.750000e+03 train accuracy: 0.390612 val accuracy: 0.394000\n",
      "lr 1.323158e-06 reg 2.000000e+03 train accuracy: 0.381816 val accuracy: 0.383000\n",
      "lr 1.323158e-06 reg 2.250000e+03 train accuracy: 0.387347 val accuracy: 0.396000\n",
      "lr 1.323158e-06 reg 2.500000e+03 train accuracy: 0.387551 val accuracy: 0.385000\n",
      "lr 1.323158e-06 reg 2.750000e+03 train accuracy: 0.372857 val accuracy: 0.391000\n",
      "lr 1.323158e-06 reg 3.000000e+03 train accuracy: 0.372735 val accuracy: 0.392000\n",
      "lr 1.323158e-06 reg 3.250000e+03 train accuracy: 0.379551 val accuracy: 0.378000\n",
      "lr 1.323158e-06 reg 3.500000e+03 train accuracy: 0.375612 val accuracy: 0.396000\n",
      "lr 1.323158e-06 reg 3.750000e+03 train accuracy: 0.362571 val accuracy: 0.376000\n",
      "lr 1.323158e-06 reg 4.000000e+03 train accuracy: 0.368347 val accuracy: 0.377000\n",
      "lr 1.323158e-06 reg 4.250000e+03 train accuracy: 0.375408 val accuracy: 0.368000\n",
      "lr 1.323158e-06 reg 4.500000e+03 train accuracy: 0.370551 val accuracy: 0.375000\n",
      "lr 1.323158e-06 reg 4.750000e+03 train accuracy: 0.363306 val accuracy: 0.373000\n",
      "lr 1.323158e-06 reg 5.000000e+03 train accuracy: 0.358612 val accuracy: 0.377000\n",
      "lr 1.585789e-06 reg 2.500000e+02 train accuracy: 0.389347 val accuracy: 0.396000\n",
      "lr 1.585789e-06 reg 5.000000e+02 train accuracy: 0.391306 val accuracy: 0.381000\n",
      "lr 1.585789e-06 reg 7.500000e+02 train accuracy: 0.395000 val accuracy: 0.392000\n",
      "lr 1.585789e-06 reg 1.000000e+03 train accuracy: 0.399551 val accuracy: 0.411000\n",
      "lr 1.585789e-06 reg 1.250000e+03 train accuracy: 0.397653 val accuracy: 0.402000\n",
      "lr 1.585789e-06 reg 1.500000e+03 train accuracy: 0.389286 val accuracy: 0.398000\n",
      "lr 1.585789e-06 reg 1.750000e+03 train accuracy: 0.388755 val accuracy: 0.390000\n",
      "lr 1.585789e-06 reg 2.000000e+03 train accuracy: 0.387429 val accuracy: 0.393000\n",
      "lr 1.585789e-06 reg 2.250000e+03 train accuracy: 0.387143 val accuracy: 0.387000\n",
      "lr 1.585789e-06 reg 2.500000e+03 train accuracy: 0.382408 val accuracy: 0.374000\n",
      "lr 1.585789e-06 reg 2.750000e+03 train accuracy: 0.375469 val accuracy: 0.371000\n",
      "lr 1.585789e-06 reg 3.000000e+03 train accuracy: 0.380061 val accuracy: 0.380000\n",
      "lr 1.585789e-06 reg 3.250000e+03 train accuracy: 0.376449 val accuracy: 0.382000\n",
      "lr 1.585789e-06 reg 3.500000e+03 train accuracy: 0.373898 val accuracy: 0.365000\n",
      "lr 1.585789e-06 reg 3.750000e+03 train accuracy: 0.365000 val accuracy: 0.371000\n",
      "lr 1.585789e-06 reg 4.000000e+03 train accuracy: 0.378286 val accuracy: 0.402000\n",
      "lr 1.585789e-06 reg 4.250000e+03 train accuracy: 0.366327 val accuracy: 0.381000\n",
      "lr 1.585789e-06 reg 4.500000e+03 train accuracy: 0.363388 val accuracy: 0.360000\n",
      "lr 1.585789e-06 reg 4.750000e+03 train accuracy: 0.363959 val accuracy: 0.376000\n",
      "lr 1.585789e-06 reg 5.000000e+03 train accuracy: 0.360490 val accuracy: 0.363000\n",
      "lr 1.848421e-06 reg 2.500000e+02 train accuracy: 0.386469 val accuracy: 0.397000\n",
      "lr 1.848421e-06 reg 5.000000e+02 train accuracy: 0.398551 val accuracy: 0.397000\n",
      "lr 1.848421e-06 reg 7.500000e+02 train accuracy: 0.396449 val accuracy: 0.403000\n",
      "lr 1.848421e-06 reg 1.000000e+03 train accuracy: 0.395408 val accuracy: 0.395000\n",
      "lr 1.848421e-06 reg 1.250000e+03 train accuracy: 0.390531 val accuracy: 0.410000\n",
      "lr 1.848421e-06 reg 1.500000e+03 train accuracy: 0.383245 val accuracy: 0.377000\n",
      "lr 1.848421e-06 reg 1.750000e+03 train accuracy: 0.391694 val accuracy: 0.397000\n",
      "lr 1.848421e-06 reg 2.000000e+03 train accuracy: 0.378469 val accuracy: 0.388000\n",
      "lr 1.848421e-06 reg 2.250000e+03 train accuracy: 0.364449 val accuracy: 0.353000\n",
      "lr 1.848421e-06 reg 2.500000e+03 train accuracy: 0.377429 val accuracy: 0.384000\n",
      "lr 1.848421e-06 reg 2.750000e+03 train accuracy: 0.360306 val accuracy: 0.373000\n",
      "lr 1.848421e-06 reg 3.000000e+03 train accuracy: 0.380347 val accuracy: 0.364000\n",
      "lr 1.848421e-06 reg 3.250000e+03 train accuracy: 0.363714 val accuracy: 0.357000\n",
      "lr 1.848421e-06 reg 3.500000e+03 train accuracy: 0.358184 val accuracy: 0.369000\n",
      "lr 1.848421e-06 reg 3.750000e+03 train accuracy: 0.361980 val accuracy: 0.377000\n",
      "lr 1.848421e-06 reg 4.000000e+03 train accuracy: 0.344020 val accuracy: 0.346000\n",
      "lr 1.848421e-06 reg 4.250000e+03 train accuracy: 0.361694 val accuracy: 0.374000\n",
      "lr 1.848421e-06 reg 4.500000e+03 train accuracy: 0.361163 val accuracy: 0.375000\n",
      "lr 1.848421e-06 reg 4.750000e+03 train accuracy: 0.357653 val accuracy: 0.377000\n",
      "lr 1.848421e-06 reg 5.000000e+03 train accuracy: 0.360143 val accuracy: 0.375000\n",
      "lr 2.111053e-06 reg 2.500000e+02 train accuracy: 0.393184 val accuracy: 0.394000\n",
      "lr 2.111053e-06 reg 5.000000e+02 train accuracy: 0.377898 val accuracy: 0.386000\n",
      "lr 2.111053e-06 reg 7.500000e+02 train accuracy: 0.390102 val accuracy: 0.405000\n",
      "lr 2.111053e-06 reg 1.000000e+03 train accuracy: 0.396571 val accuracy: 0.397000\n",
      "lr 2.111053e-06 reg 1.250000e+03 train accuracy: 0.395245 val accuracy: 0.404000\n",
      "lr 2.111053e-06 reg 1.500000e+03 train accuracy: 0.376755 val accuracy: 0.379000\n",
      "lr 2.111053e-06 reg 1.750000e+03 train accuracy: 0.381245 val accuracy: 0.404000\n",
      "lr 2.111053e-06 reg 2.000000e+03 train accuracy: 0.380857 val accuracy: 0.387000\n",
      "lr 2.111053e-06 reg 2.250000e+03 train accuracy: 0.373265 val accuracy: 0.361000\n",
      "lr 2.111053e-06 reg 2.500000e+03 train accuracy: 0.372163 val accuracy: 0.385000\n",
      "lr 2.111053e-06 reg 2.750000e+03 train accuracy: 0.376306 val accuracy: 0.381000\n",
      "lr 2.111053e-06 reg 3.000000e+03 train accuracy: 0.367878 val accuracy: 0.364000\n",
      "lr 2.111053e-06 reg 3.250000e+03 train accuracy: 0.374490 val accuracy: 0.377000\n",
      "lr 2.111053e-06 reg 3.500000e+03 train accuracy: 0.365163 val accuracy: 0.375000\n",
      "lr 2.111053e-06 reg 3.750000e+03 train accuracy: 0.364959 val accuracy: 0.360000\n",
      "lr 2.111053e-06 reg 4.000000e+03 train accuracy: 0.366000 val accuracy: 0.373000\n",
      "lr 2.111053e-06 reg 4.250000e+03 train accuracy: 0.357592 val accuracy: 0.363000\n",
      "lr 2.111053e-06 reg 4.500000e+03 train accuracy: 0.361122 val accuracy: 0.345000\n",
      "lr 2.111053e-06 reg 4.750000e+03 train accuracy: 0.363041 val accuracy: 0.370000\n",
      "lr 2.111053e-06 reg 5.000000e+03 train accuracy: 0.349980 val accuracy: 0.359000\n",
      "lr 2.373684e-06 reg 2.500000e+02 train accuracy: 0.388265 val accuracy: 0.399000\n",
      "lr 2.373684e-06 reg 5.000000e+02 train accuracy: 0.398551 val accuracy: 0.406000\n",
      "lr 2.373684e-06 reg 7.500000e+02 train accuracy: 0.393571 val accuracy: 0.372000\n",
      "lr 2.373684e-06 reg 1.000000e+03 train accuracy: 0.387776 val accuracy: 0.401000\n",
      "lr 2.373684e-06 reg 1.250000e+03 train accuracy: 0.388735 val accuracy: 0.402000\n",
      "lr 2.373684e-06 reg 1.500000e+03 train accuracy: 0.372878 val accuracy: 0.382000\n",
      "lr 2.373684e-06 reg 1.750000e+03 train accuracy: 0.368857 val accuracy: 0.371000\n",
      "lr 2.373684e-06 reg 2.000000e+03 train accuracy: 0.368878 val accuracy: 0.372000\n",
      "lr 2.373684e-06 reg 2.250000e+03 train accuracy: 0.383224 val accuracy: 0.392000\n",
      "lr 2.373684e-06 reg 2.500000e+03 train accuracy: 0.364633 val accuracy: 0.392000\n",
      "lr 2.373684e-06 reg 2.750000e+03 train accuracy: 0.366184 val accuracy: 0.367000\n",
      "lr 2.373684e-06 reg 3.000000e+03 train accuracy: 0.361939 val accuracy: 0.363000\n",
      "lr 2.373684e-06 reg 3.250000e+03 train accuracy: 0.362531 val accuracy: 0.362000\n",
      "lr 2.373684e-06 reg 3.500000e+03 train accuracy: 0.366898 val accuracy: 0.368000\n",
      "lr 2.373684e-06 reg 3.750000e+03 train accuracy: 0.361306 val accuracy: 0.368000\n",
      "lr 2.373684e-06 reg 4.000000e+03 train accuracy: 0.364143 val accuracy: 0.361000\n",
      "lr 2.373684e-06 reg 4.250000e+03 train accuracy: 0.368265 val accuracy: 0.381000\n",
      "lr 2.373684e-06 reg 4.500000e+03 train accuracy: 0.359857 val accuracy: 0.377000\n",
      "lr 2.373684e-06 reg 4.750000e+03 train accuracy: 0.340102 val accuracy: 0.342000\n",
      "lr 2.373684e-06 reg 5.000000e+03 train accuracy: 0.352327 val accuracy: 0.364000\n",
      "lr 2.636316e-06 reg 2.500000e+02 train accuracy: 0.386306 val accuracy: 0.404000\n",
      "lr 2.636316e-06 reg 5.000000e+02 train accuracy: 0.394694 val accuracy: 0.397000\n",
      "lr 2.636316e-06 reg 7.500000e+02 train accuracy: 0.389388 val accuracy: 0.381000\n",
      "lr 2.636316e-06 reg 1.000000e+03 train accuracy: 0.383510 val accuracy: 0.389000\n",
      "lr 2.636316e-06 reg 1.250000e+03 train accuracy: 0.384673 val accuracy: 0.382000\n",
      "lr 2.636316e-06 reg 1.500000e+03 train accuracy: 0.382204 val accuracy: 0.378000\n",
      "lr 2.636316e-06 reg 1.750000e+03 train accuracy: 0.367265 val accuracy: 0.363000\n",
      "lr 2.636316e-06 reg 2.000000e+03 train accuracy: 0.378388 val accuracy: 0.383000\n",
      "lr 2.636316e-06 reg 2.250000e+03 train accuracy: 0.368429 val accuracy: 0.380000\n",
      "lr 2.636316e-06 reg 2.500000e+03 train accuracy: 0.357122 val accuracy: 0.361000\n",
      "lr 2.636316e-06 reg 2.750000e+03 train accuracy: 0.355571 val accuracy: 0.356000\n",
      "lr 2.636316e-06 reg 3.000000e+03 train accuracy: 0.367714 val accuracy: 0.383000\n",
      "lr 2.636316e-06 reg 3.250000e+03 train accuracy: 0.351571 val accuracy: 0.373000\n",
      "lr 2.636316e-06 reg 3.500000e+03 train accuracy: 0.348306 val accuracy: 0.349000\n",
      "lr 2.636316e-06 reg 3.750000e+03 train accuracy: 0.362980 val accuracy: 0.361000\n",
      "lr 2.636316e-06 reg 4.000000e+03 train accuracy: 0.348020 val accuracy: 0.345000\n",
      "lr 2.636316e-06 reg 4.250000e+03 train accuracy: 0.333673 val accuracy: 0.342000\n",
      "lr 2.636316e-06 reg 4.500000e+03 train accuracy: 0.335816 val accuracy: 0.338000\n",
      "lr 2.636316e-06 reg 4.750000e+03 train accuracy: 0.355714 val accuracy: 0.349000\n",
      "lr 2.636316e-06 reg 5.000000e+03 train accuracy: 0.340510 val accuracy: 0.346000\n",
      "lr 2.898947e-06 reg 2.500000e+02 train accuracy: 0.368612 val accuracy: 0.347000\n",
      "lr 2.898947e-06 reg 5.000000e+02 train accuracy: 0.396286 val accuracy: 0.406000\n",
      "lr 2.898947e-06 reg 7.500000e+02 train accuracy: 0.393816 val accuracy: 0.387000\n",
      "lr 2.898947e-06 reg 1.000000e+03 train accuracy: 0.370857 val accuracy: 0.378000\n",
      "lr 2.898947e-06 reg 1.250000e+03 train accuracy: 0.370857 val accuracy: 0.359000\n",
      "lr 2.898947e-06 reg 1.500000e+03 train accuracy: 0.366204 val accuracy: 0.366000\n",
      "lr 2.898947e-06 reg 1.750000e+03 train accuracy: 0.378347 val accuracy: 0.382000\n",
      "lr 2.898947e-06 reg 2.000000e+03 train accuracy: 0.366755 val accuracy: 0.366000\n",
      "lr 2.898947e-06 reg 2.250000e+03 train accuracy: 0.374306 val accuracy: 0.396000\n",
      "lr 2.898947e-06 reg 2.500000e+03 train accuracy: 0.352408 val accuracy: 0.352000\n",
      "lr 2.898947e-06 reg 2.750000e+03 train accuracy: 0.368327 val accuracy: 0.384000\n",
      "lr 2.898947e-06 reg 3.000000e+03 train accuracy: 0.365816 val accuracy: 0.388000\n",
      "lr 2.898947e-06 reg 3.250000e+03 train accuracy: 0.344510 val accuracy: 0.349000\n",
      "lr 2.898947e-06 reg 3.500000e+03 train accuracy: 0.357735 val accuracy: 0.359000\n",
      "lr 2.898947e-06 reg 3.750000e+03 train accuracy: 0.352327 val accuracy: 0.365000\n",
      "lr 2.898947e-06 reg 4.000000e+03 train accuracy: 0.347286 val accuracy: 0.349000\n",
      "lr 2.898947e-06 reg 4.250000e+03 train accuracy: 0.349020 val accuracy: 0.355000\n",
      "lr 2.898947e-06 reg 4.500000e+03 train accuracy: 0.335143 val accuracy: 0.338000\n",
      "lr 2.898947e-06 reg 4.750000e+03 train accuracy: 0.345592 val accuracy: 0.360000\n",
      "lr 2.898947e-06 reg 5.000000e+03 train accuracy: 0.345510 val accuracy: 0.364000\n",
      "lr 3.161579e-06 reg 2.500000e+02 train accuracy: 0.377857 val accuracy: 0.355000\n",
      "lr 3.161579e-06 reg 5.000000e+02 train accuracy: 0.381143 val accuracy: 0.394000\n",
      "lr 3.161579e-06 reg 7.500000e+02 train accuracy: 0.390878 val accuracy: 0.400000\n",
      "lr 3.161579e-06 reg 1.000000e+03 train accuracy: 0.382265 val accuracy: 0.384000\n",
      "lr 3.161579e-06 reg 1.250000e+03 train accuracy: 0.383571 val accuracy: 0.380000\n",
      "lr 3.161579e-06 reg 1.500000e+03 train accuracy: 0.379224 val accuracy: 0.387000\n",
      "lr 3.161579e-06 reg 1.750000e+03 train accuracy: 0.366163 val accuracy: 0.376000\n",
      "lr 3.161579e-06 reg 2.000000e+03 train accuracy: 0.367327 val accuracy: 0.365000\n",
      "lr 3.161579e-06 reg 2.250000e+03 train accuracy: 0.357837 val accuracy: 0.341000\n",
      "lr 3.161579e-06 reg 2.500000e+03 train accuracy: 0.352694 val accuracy: 0.365000\n",
      "lr 3.161579e-06 reg 2.750000e+03 train accuracy: 0.362571 val accuracy: 0.379000\n",
      "lr 3.161579e-06 reg 3.000000e+03 train accuracy: 0.346571 val accuracy: 0.363000\n",
      "lr 3.161579e-06 reg 3.250000e+03 train accuracy: 0.350959 val accuracy: 0.354000\n",
      "lr 3.161579e-06 reg 3.500000e+03 train accuracy: 0.347306 val accuracy: 0.384000\n",
      "lr 3.161579e-06 reg 3.750000e+03 train accuracy: 0.361163 val accuracy: 0.389000\n",
      "lr 3.161579e-06 reg 4.000000e+03 train accuracy: 0.346776 val accuracy: 0.355000\n",
      "lr 3.161579e-06 reg 4.250000e+03 train accuracy: 0.350082 val accuracy: 0.347000\n",
      "lr 3.161579e-06 reg 4.500000e+03 train accuracy: 0.348449 val accuracy: 0.351000\n",
      "lr 3.161579e-06 reg 4.750000e+03 train accuracy: 0.340673 val accuracy: 0.328000\n",
      "lr 3.161579e-06 reg 5.000000e+03 train accuracy: 0.350592 val accuracy: 0.347000\n",
      "lr 3.424211e-06 reg 2.500000e+02 train accuracy: 0.383673 val accuracy: 0.381000\n",
      "lr 3.424211e-06 reg 5.000000e+02 train accuracy: 0.385000 val accuracy: 0.381000\n",
      "lr 3.424211e-06 reg 7.500000e+02 train accuracy: 0.372592 val accuracy: 0.394000\n",
      "lr 3.424211e-06 reg 1.000000e+03 train accuracy: 0.363735 val accuracy: 0.339000\n",
      "lr 3.424211e-06 reg 1.250000e+03 train accuracy: 0.384918 val accuracy: 0.382000\n",
      "lr 3.424211e-06 reg 1.500000e+03 train accuracy: 0.360000 val accuracy: 0.357000\n",
      "lr 3.424211e-06 reg 1.750000e+03 train accuracy: 0.371490 val accuracy: 0.366000\n",
      "lr 3.424211e-06 reg 2.000000e+03 train accuracy: 0.369510 val accuracy: 0.378000\n",
      "lr 3.424211e-06 reg 2.250000e+03 train accuracy: 0.357878 val accuracy: 0.370000\n",
      "lr 3.424211e-06 reg 2.500000e+03 train accuracy: 0.349939 val accuracy: 0.355000\n",
      "lr 3.424211e-06 reg 2.750000e+03 train accuracy: 0.359286 val accuracy: 0.354000\n",
      "lr 3.424211e-06 reg 3.000000e+03 train accuracy: 0.338633 val accuracy: 0.342000\n",
      "lr 3.424211e-06 reg 3.250000e+03 train accuracy: 0.357857 val accuracy: 0.355000\n",
      "lr 3.424211e-06 reg 3.500000e+03 train accuracy: 0.353408 val accuracy: 0.363000\n",
      "lr 3.424211e-06 reg 3.750000e+03 train accuracy: 0.348122 val accuracy: 0.342000\n",
      "lr 3.424211e-06 reg 4.000000e+03 train accuracy: 0.319082 val accuracy: 0.317000\n",
      "lr 3.424211e-06 reg 4.250000e+03 train accuracy: 0.346776 val accuracy: 0.360000\n",
      "lr 3.424211e-06 reg 4.500000e+03 train accuracy: 0.340571 val accuracy: 0.346000\n",
      "lr 3.424211e-06 reg 4.750000e+03 train accuracy: 0.320816 val accuracy: 0.325000\n",
      "lr 3.424211e-06 reg 5.000000e+03 train accuracy: 0.339980 val accuracy: 0.350000\n",
      "lr 3.686842e-06 reg 2.500000e+02 train accuracy: 0.366673 val accuracy: 0.369000\n",
      "lr 3.686842e-06 reg 5.000000e+02 train accuracy: 0.376612 val accuracy: 0.384000\n",
      "lr 3.686842e-06 reg 7.500000e+02 train accuracy: 0.374204 val accuracy: 0.382000\n",
      "lr 3.686842e-06 reg 1.000000e+03 train accuracy: 0.370184 val accuracy: 0.371000\n",
      "lr 3.686842e-06 reg 1.250000e+03 train accuracy: 0.365469 val accuracy: 0.356000\n",
      "lr 3.686842e-06 reg 1.500000e+03 train accuracy: 0.356408 val accuracy: 0.347000\n",
      "lr 3.686842e-06 reg 1.750000e+03 train accuracy: 0.349918 val accuracy: 0.351000\n",
      "lr 3.686842e-06 reg 2.000000e+03 train accuracy: 0.370408 val accuracy: 0.365000\n",
      "lr 3.686842e-06 reg 2.250000e+03 train accuracy: 0.366939 val accuracy: 0.383000\n",
      "lr 3.686842e-06 reg 2.500000e+03 train accuracy: 0.349857 val accuracy: 0.360000\n",
      "lr 3.686842e-06 reg 2.750000e+03 train accuracy: 0.356061 val accuracy: 0.359000\n",
      "lr 3.686842e-06 reg 3.000000e+03 train accuracy: 0.332041 val accuracy: 0.346000\n",
      "lr 3.686842e-06 reg 3.250000e+03 train accuracy: 0.350184 val accuracy: 0.348000\n",
      "lr 3.686842e-06 reg 3.500000e+03 train accuracy: 0.342388 val accuracy: 0.366000\n",
      "lr 3.686842e-06 reg 3.750000e+03 train accuracy: 0.350490 val accuracy: 0.367000\n",
      "lr 3.686842e-06 reg 4.000000e+03 train accuracy: 0.295612 val accuracy: 0.300000\n",
      "lr 3.686842e-06 reg 4.250000e+03 train accuracy: 0.340041 val accuracy: 0.343000\n",
      "lr 3.686842e-06 reg 4.500000e+03 train accuracy: 0.330673 val accuracy: 0.336000\n",
      "lr 3.686842e-06 reg 4.750000e+03 train accuracy: 0.309082 val accuracy: 0.302000\n",
      "lr 3.686842e-06 reg 5.000000e+03 train accuracy: 0.320918 val accuracy: 0.325000\n",
      "lr 3.949474e-06 reg 2.500000e+02 train accuracy: 0.377306 val accuracy: 0.378000\n",
      "lr 3.949474e-06 reg 5.000000e+02 train accuracy: 0.363939 val accuracy: 0.360000\n",
      "lr 3.949474e-06 reg 7.500000e+02 train accuracy: 0.355939 val accuracy: 0.350000\n",
      "lr 3.949474e-06 reg 1.000000e+03 train accuracy: 0.366327 val accuracy: 0.352000\n",
      "lr 3.949474e-06 reg 1.250000e+03 train accuracy: 0.384735 val accuracy: 0.387000\n",
      "lr 3.949474e-06 reg 1.500000e+03 train accuracy: 0.358612 val accuracy: 0.380000\n",
      "lr 3.949474e-06 reg 1.750000e+03 train accuracy: 0.354143 val accuracy: 0.356000\n",
      "lr 3.949474e-06 reg 2.000000e+03 train accuracy: 0.355714 val accuracy: 0.363000\n",
      "lr 3.949474e-06 reg 2.250000e+03 train accuracy: 0.353531 val accuracy: 0.364000\n",
      "lr 3.949474e-06 reg 2.500000e+03 train accuracy: 0.356959 val accuracy: 0.366000\n",
      "lr 3.949474e-06 reg 2.750000e+03 train accuracy: 0.352980 val accuracy: 0.365000\n",
      "lr 3.949474e-06 reg 3.000000e+03 train accuracy: 0.334286 val accuracy: 0.339000\n",
      "lr 3.949474e-06 reg 3.250000e+03 train accuracy: 0.329449 val accuracy: 0.324000\n",
      "lr 3.949474e-06 reg 3.500000e+03 train accuracy: 0.340449 val accuracy: 0.355000\n",
      "lr 3.949474e-06 reg 3.750000e+03 train accuracy: 0.326571 val accuracy: 0.342000\n",
      "lr 3.949474e-06 reg 4.000000e+03 train accuracy: 0.327327 val accuracy: 0.342000\n",
      "lr 3.949474e-06 reg 4.250000e+03 train accuracy: 0.327306 val accuracy: 0.330000\n",
      "lr 3.949474e-06 reg 4.500000e+03 train accuracy: 0.342796 val accuracy: 0.327000\n",
      "lr 3.949474e-06 reg 4.750000e+03 train accuracy: 0.337776 val accuracy: 0.345000\n",
      "lr 3.949474e-06 reg 5.000000e+03 train accuracy: 0.317776 val accuracy: 0.337000\n",
      "lr 4.212105e-06 reg 2.500000e+02 train accuracy: 0.344000 val accuracy: 0.353000\n",
      "lr 4.212105e-06 reg 5.000000e+02 train accuracy: 0.383694 val accuracy: 0.380000\n",
      "lr 4.212105e-06 reg 7.500000e+02 train accuracy: 0.383102 val accuracy: 0.378000\n",
      "lr 4.212105e-06 reg 1.000000e+03 train accuracy: 0.370286 val accuracy: 0.371000\n",
      "lr 4.212105e-06 reg 1.250000e+03 train accuracy: 0.364245 val accuracy: 0.358000\n",
      "lr 4.212105e-06 reg 1.500000e+03 train accuracy: 0.367980 val accuracy: 0.375000\n",
      "lr 4.212105e-06 reg 1.750000e+03 train accuracy: 0.342163 val accuracy: 0.345000\n",
      "lr 4.212105e-06 reg 2.000000e+03 train accuracy: 0.342347 val accuracy: 0.351000\n",
      "lr 4.212105e-06 reg 2.250000e+03 train accuracy: 0.321551 val accuracy: 0.333000\n",
      "lr 4.212105e-06 reg 2.500000e+03 train accuracy: 0.343531 val accuracy: 0.348000\n",
      "lr 4.212105e-06 reg 2.750000e+03 train accuracy: 0.340082 val accuracy: 0.344000\n",
      "lr 4.212105e-06 reg 3.000000e+03 train accuracy: 0.336306 val accuracy: 0.351000\n",
      "lr 4.212105e-06 reg 3.250000e+03 train accuracy: 0.320163 val accuracy: 0.317000\n",
      "lr 4.212105e-06 reg 3.500000e+03 train accuracy: 0.327592 val accuracy: 0.323000\n",
      "lr 4.212105e-06 reg 3.750000e+03 train accuracy: 0.316694 val accuracy: 0.318000\n",
      "lr 4.212105e-06 reg 4.000000e+03 train accuracy: 0.327347 val accuracy: 0.340000\n",
      "lr 4.212105e-06 reg 4.250000e+03 train accuracy: 0.311898 val accuracy: 0.317000\n",
      "lr 4.212105e-06 reg 4.500000e+03 train accuracy: 0.333449 val accuracy: 0.327000\n",
      "lr 4.212105e-06 reg 4.750000e+03 train accuracy: 0.306224 val accuracy: 0.295000\n",
      "lr 4.212105e-06 reg 5.000000e+03 train accuracy: 0.336551 val accuracy: 0.345000\n",
      "lr 4.474737e-06 reg 2.500000e+02 train accuracy: 0.361327 val accuracy: 0.351000\n",
      "lr 4.474737e-06 reg 5.000000e+02 train accuracy: 0.386714 val accuracy: 0.380000\n",
      "lr 4.474737e-06 reg 7.500000e+02 train accuracy: 0.381571 val accuracy: 0.385000\n",
      "lr 4.474737e-06 reg 1.000000e+03 train accuracy: 0.352429 val accuracy: 0.341000\n",
      "lr 4.474737e-06 reg 1.250000e+03 train accuracy: 0.351327 val accuracy: 0.348000\n",
      "lr 4.474737e-06 reg 1.500000e+03 train accuracy: 0.369245 val accuracy: 0.375000\n",
      "lr 4.474737e-06 reg 1.750000e+03 train accuracy: 0.367510 val accuracy: 0.372000\n",
      "lr 4.474737e-06 reg 2.000000e+03 train accuracy: 0.352041 val accuracy: 0.370000\n",
      "lr 4.474737e-06 reg 2.250000e+03 train accuracy: 0.343102 val accuracy: 0.369000\n",
      "lr 4.474737e-06 reg 2.500000e+03 train accuracy: 0.329653 val accuracy: 0.335000\n",
      "lr 4.474737e-06 reg 2.750000e+03 train accuracy: 0.330714 val accuracy: 0.346000\n",
      "lr 4.474737e-06 reg 3.000000e+03 train accuracy: 0.324327 val accuracy: 0.311000\n",
      "lr 4.474737e-06 reg 3.250000e+03 train accuracy: 0.329735 val accuracy: 0.350000\n",
      "lr 4.474737e-06 reg 3.500000e+03 train accuracy: 0.329959 val accuracy: 0.344000\n",
      "lr 4.474737e-06 reg 3.750000e+03 train accuracy: 0.335959 val accuracy: 0.347000\n",
      "lr 4.474737e-06 reg 4.000000e+03 train accuracy: 0.350245 val accuracy: 0.351000\n",
      "lr 4.474737e-06 reg 4.250000e+03 train accuracy: 0.328408 val accuracy: 0.359000\n",
      "lr 4.474737e-06 reg 4.500000e+03 train accuracy: 0.317286 val accuracy: 0.320000\n",
      "lr 4.474737e-06 reg 4.750000e+03 train accuracy: 0.307857 val accuracy: 0.326000\n",
      "lr 4.474737e-06 reg 5.000000e+03 train accuracy: 0.326327 val accuracy: 0.321000\n",
      "lr 4.737368e-06 reg 2.500000e+02 train accuracy: 0.358061 val accuracy: 0.377000\n",
      "lr 4.737368e-06 reg 5.000000e+02 train accuracy: 0.377714 val accuracy: 0.374000\n",
      "lr 4.737368e-06 reg 7.500000e+02 train accuracy: 0.365347 val accuracy: 0.377000\n",
      "lr 4.737368e-06 reg 1.000000e+03 train accuracy: 0.338918 val accuracy: 0.342000\n",
      "lr 4.737368e-06 reg 1.250000e+03 train accuracy: 0.340449 val accuracy: 0.328000\n",
      "lr 4.737368e-06 reg 1.500000e+03 train accuracy: 0.355898 val accuracy: 0.374000\n",
      "lr 4.737368e-06 reg 1.750000e+03 train accuracy: 0.318469 val accuracy: 0.323000\n",
      "lr 4.737368e-06 reg 2.000000e+03 train accuracy: 0.307122 val accuracy: 0.318000\n",
      "lr 4.737368e-06 reg 2.250000e+03 train accuracy: 0.335898 val accuracy: 0.346000\n",
      "lr 4.737368e-06 reg 2.500000e+03 train accuracy: 0.342551 val accuracy: 0.333000\n",
      "lr 4.737368e-06 reg 2.750000e+03 train accuracy: 0.331633 val accuracy: 0.346000\n",
      "lr 4.737368e-06 reg 3.000000e+03 train accuracy: 0.302796 val accuracy: 0.297000\n",
      "lr 4.737368e-06 reg 3.250000e+03 train accuracy: 0.288959 val accuracy: 0.296000\n",
      "lr 4.737368e-06 reg 3.500000e+03 train accuracy: 0.326327 val accuracy: 0.305000\n",
      "lr 4.737368e-06 reg 3.750000e+03 train accuracy: 0.308000 val accuracy: 0.318000\n",
      "lr 4.737368e-06 reg 4.000000e+03 train accuracy: 0.298265 val accuracy: 0.290000\n",
      "lr 4.737368e-06 reg 4.250000e+03 train accuracy: 0.301694 val accuracy: 0.313000\n",
      "lr 4.737368e-06 reg 4.500000e+03 train accuracy: 0.300224 val accuracy: 0.292000\n",
      "lr 4.737368e-06 reg 4.750000e+03 train accuracy: 0.316673 val accuracy: 0.318000\n",
      "lr 4.737368e-06 reg 5.000000e+03 train accuracy: 0.333510 val accuracy: 0.355000\n",
      "lr 5.000000e-06 reg 2.500000e+02 train accuracy: 0.353061 val accuracy: 0.364000\n",
      "lr 5.000000e-06 reg 5.000000e+02 train accuracy: 0.357796 val accuracy: 0.360000\n",
      "lr 5.000000e-06 reg 7.500000e+02 train accuracy: 0.361469 val accuracy: 0.359000\n",
      "lr 5.000000e-06 reg 1.000000e+03 train accuracy: 0.342551 val accuracy: 0.331000\n",
      "lr 5.000000e-06 reg 1.250000e+03 train accuracy: 0.323347 val accuracy: 0.318000\n",
      "lr 5.000000e-06 reg 1.500000e+03 train accuracy: 0.332898 val accuracy: 0.316000\n",
      "lr 5.000000e-06 reg 1.750000e+03 train accuracy: 0.326878 val accuracy: 0.342000\n",
      "lr 5.000000e-06 reg 2.000000e+03 train accuracy: 0.319735 val accuracy: 0.327000\n",
      "lr 5.000000e-06 reg 2.250000e+03 train accuracy: 0.302184 val accuracy: 0.312000\n",
      "lr 5.000000e-06 reg 2.500000e+03 train accuracy: 0.341184 val accuracy: 0.364000\n",
      "lr 5.000000e-06 reg 2.750000e+03 train accuracy: 0.328776 val accuracy: 0.349000\n",
      "lr 5.000000e-06 reg 3.000000e+03 train accuracy: 0.310061 val accuracy: 0.315000\n",
      "lr 5.000000e-06 reg 3.250000e+03 train accuracy: 0.283918 val accuracy: 0.292000\n",
      "lr 5.000000e-06 reg 3.500000e+03 train accuracy: 0.297408 val accuracy: 0.313000\n",
      "lr 5.000000e-06 reg 3.750000e+03 train accuracy: 0.308163 val accuracy: 0.301000\n",
      "lr 5.000000e-06 reg 4.000000e+03 train accuracy: 0.305633 val accuracy: 0.316000\n",
      "lr 5.000000e-06 reg 4.250000e+03 train accuracy: 0.306878 val accuracy: 0.321000\n",
      "lr 5.000000e-06 reg 4.500000e+03 train accuracy: 0.307531 val accuracy: 0.312000\n",
      "lr 5.000000e-06 reg 4.750000e+03 train accuracy: 0.310531 val accuracy: 0.320000\n",
      "lr 5.000000e-06 reg 5.000000e+03 train accuracy: 0.300041 val accuracy: 0.313000\n",
      "best validation accuracy achieved during cross-validation: 0.411000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = np.linspace(1e-8, 5e-6, 20) \n",
    "regularization_strengths = np.linspace(2.5e2, 5e3, 20)\n",
    "# learning_rates = [1e-7, 5e-7]\n",
    "# regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "softmax = Softmax()\n",
    "for lr in tqdm_notebook(learning_rates, total = len(learning_rates),  mininterval=1):\n",
    "    for reg in regularization_strengths:\n",
    "        loss_hist = softmax.train(X_train, y_train, learning_rate=lr, reg=reg,\n",
    "                      num_iters=100, verbose=False)\n",
    "        y_train_acc = np.mean(y_train == softmax.predict(X_train))\n",
    "        y_val_acc = np.mean(y_val == softmax.predict(X_val))\n",
    "        results[(lr, reg)] = (y_train_acc, y_val_acc)\n",
    "        if y_val_acc > best_val:\n",
    "            best_val = y_val_acc\n",
    "            best_softmax = softmax \n",
    "            best_lr = lr\n",
    "            best_reg = reg\n",
    "\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.318000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.212105263157895e-06, 750.0)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr, best_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*:\n",
    "\n",
    "*Your explanation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
